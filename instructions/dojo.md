summary: dojo - cicd devops
id: dojo 
categories: exercice 
tags: exercice 
status: Published 
authors: ANTE
Feedback Link: https://github.com/tehioant/Dojo-cicd-devops-octo/issues/new

# DOJO - CI/CD DevOps

## Overview

Duration: 4 hours

Objectifs pÃ©dagogique :

- DÃ©couvrir les concepts autour de l'intÃ©gration continue,
- Programmer un pipeline d'intÃ©gration continue/une usine de dÃ©veloppement logiciel,
- Obtenir du feedback frÃ©quemment grÃ¢ce aux tests automatisÃ©s,
- Mesurer la qualitÃ© de son code,
- Automatiser la production d'artÃ©facts,
- Creer une pipeline de release par tag.

ğŸ‘‰ [Dispo sur le drive OCTO](https://docs.google.com/presentation/d/1kRS86ba0FT6grKMrwFyHaTTzEwl_cAeZE8Euqx3e9kM/edit#slide=id.g804284dca3_0_176).

## Presentation

Duration: ?

### Environment

Ce produit comprend une Azure Function App `func-dojo-cicd-skool` composÃ© d'une fonctino en typescript nommÃ© `DojoCicdSkool`.\
Les developpeurs construisent une API.
Pour permettre cela et produire du code de qualitÃ©, il faut de l'automatisation et de l'outillage ğŸ› 
Cet outillage, c'est gÃ©nÃ©ralement un pipeline, et on va en construire une utilisant Github actions pendant ce dojo ğŸ’ƒ

Le repository a 2 pipelines qui ont besoin d'Ãªtre crÃ©Ã©
* ci.yml
* release.yml


```text
Definition:
Continuous Integration is a software development practice where members of a team 
integrate their work frequently, usually each person integrates at least daily, 
leading to multiple integrations per day.
```

La pipeline doit contenir les jobs suivants:
- Lint
- Unit tests
- Build
- Integration tests

![](./docs/pipeline-dojo.png)

Pour les curieux qui veulent aller + loin sur la notion d'intÃ©gration continue :

- <https://www.martinfowler.com/articles/continuousIntegration.html>
- <https://blog.octo.com/tag/continuous-integration/>

## Step 1 - Tests automatisÃ©s

**ğŸ¯ Goal** : je veux obtenir du feedback sur le produit que je dÃ©veloppe via les tests

### Local testing

```plaintext
> ğŸ•µï¸â€ Automatiser, c'est rendre automatique une action qui Ã©tait jusque-lÃ  manuelle ğŸ’ª
```

**ğŸ‘‰ First, run tests on you computer !** 

Au passage, prenez en note dans un fichier :
- les prÃ©-requis : les commandes ou paquets que vous avez dÃ» installer pour pouvoir lancer les tests,
- le rÃ©sultat attendu : logs affichÃ©s en console, fichiers de rapport produits, ...

ğŸ Exemple de rÃ©sultat attendu en lanÃ§ant les tests en local avec

```shell
$ npm test
```

![](./docs/local-tests-jest.png)

### Tips

Vous pouvez utiliser Makefile pour opÃ©rer votre projet et faciliter son utilisation par tous.\
Par example: ```$ make test```

## Step 2 - Tests automatisÃ©s (CI)

**ğŸ¯ Objectif** : Je veux obtenir du feedback sur mes tests Ã  chaque commit poussÃ© sur ma branche de travail.

**Rendu attendu Ã  la fin de ce TP2** : en poussant du code sur ma branche de travail, un pipeline doit se lancer automatiquement sur github. Cette pipeline doit permettre d'exÃ©cuter les tests avec jest, comme ceci quand les tests sont au vert :

![](./docs/exercise1-tests.png)

### Tests dans le pipeline de CI

ğŸ‘‰ Edit the following file [ci.yml](../.github/workflows/ci.yml) and add a stage named `function-tests`.



|                   .                   |                   .                   |
|:-------------------------------------:|:-------------------------------------:|
| âœ… SuccÃ¨s si tous les tests sont verts | ğŸ”´ Echec si au moins 1 test est rouge |
|    ![](./docs/exercise1-tests.png)    |     ![](./docs/exercise1-red.png)     |

**ğŸ Test de recette** : Si la step `function-tests` s'exÃ©cute bien dans votre pipeline de CI,
- elle devrait arborer une coche verte, 
  - ![](./docs/exercise1-tests.png) 
- et afficher les logs d'exÃ©cution de la commande pytest en console.
  - ![](./docs/exercice1-logs-tests-en-ci.png)

â„¹ï¸ Si vous ne savez pas comment faire Ã©diter le pipeline, la partie ci-aprÃ¨s vous donnera un premier vernis sur les pipelines github et leur dÃ©claration en YAML.

```yaml
## Un exemple de fichier ci.yml

env:
  FOO: bar

jobs:
  example-variable-1:
    runs-on: ubuntu-latest
    steps:
      - run: echo â€œ$FOOâ€ # bar

  example-variable-2:
    runs-on: ubuntu-latest
    env:
      FOO: override_at_job_level
    steps:
      - run: echo â€œ$FOOâ€ # override_at_job_level
```

## Step 3 - Jest report (bonus)

```plaintext
âš ï¸ Si vous vous sentez en retard; laissez de cotÃ© ce bonus; 
Vous pourrez y revenir plus tard ğŸ“… ğŸ± ğŸ”®
```

1. Dans le job `function-tests`, faites en sorte que `jest`  calcule la couverture de tests sur la fonction `DojoCicdSkool` et produise la mesure de couverture en console.
   1. Vous pouvez utiliser [la commande --coverage](https://jestjs.io/docs/cli) pour y arriver.
2. Changez la destination de production de ces rapports afin de les produire dans un dossier [reports/jest/](../reports/jest) Ã  la racine du repo.
3. Render les rapports du dossier `reports/` accessibles sous la forme d'artÃ©facts.
4. Un exemple d'utilisation de [la fonctionnalitÃ© d'artÃ©fact](https://docs.github.com/en/actions/using-workflows/storing-workflow-data-as-artifacts).

**ğŸ Test de recette : les rapports sont disponibles dans la partie Artifacts comme suit:**

![](./docs/github-artifacts.png)

## Step 4 : Mesure de la qualitÃ© du code (local)

```plaintext
ğŸ¯ Objectif : Je veux obtenir du feedback sur la qualitÃ© du code sur commande.
```

ğŸ‘¨â€ğŸ‘¨â€ğŸ‘§â€ğŸ‘¦ La qualitÃ© du code, c'est une notion subjective qui se dÃ©finit gÃ©nÃ©ralement en Ã©quipe.
ğŸ“Š Une fois qu'on l'a dÃ©fini collectivement, on peut dÃ©finir des indicateurs pour la mesurer.
ğŸ“¦ Certains package Typescript peuvent produire de tels indicateurs.

**Par exemple :**

- [es-lint](https://typescript-eslint.io/) est un linter de code TypeScript sur le style. Le nombre de warnings peut donner une indication de
la _compliance_ du code que l'on a produit avec les standards de style reconnus dans 
l'Ã©cosystÃ¨me TypeScript.
ğŸ‘‰ On pourrait dÃ©finir que du code de qualitÃ©, c'est du code qui respecte ces standards dÃ©finis par l'Ã©quipe et dont
le nombre de warning tend vers 0.
**Es-lint** inclus **prettier** dans son package. Vous pouvez dÃ©finir vos rÃ¨gles d'indentation pour conserver une continuitÃ© dans l'Ã©quipe.


- [sonarqube](https://docs.sonarqube.org/9.6/analyzing-source-code/languages/javascript-typescript-css/)
 est un outil de revue de code automatique et autogÃ©rer qui vous aide systÃ©matiquement Ã  fournir du **clean code**.
Il donne un grand nombre d'indications sur votre code et vos tests. Il permet de mesurer la couverture du code par les tests, c-a-d le ratio du nombre de lignes de code source traversÃ© par les tests sur le nombre de lignes de code total.
Il permet aussi de detecter un certains nombre de failles de sÃ©curitÃ© tant dans le code que dans les CVE (Common vulnerabilities and exposures).
ğŸ‘‰ On pourrait dÃ©finir que du code de qualitÃ©, c'est du code oÃ¹ chaque ligne est testÃ©e, 
donc du code oÃ¹ le code coverage tend vers 100% (ou du moins dÃ©passe un seuil Ã©levÃ©, ex: 80%).

- [audit-ci](https://github.com/IBM/audit-ci) est un outil concu pour le continuous integration qui nous permet de prevenir l'intÃ©gration de code et de paquets contenant des vulnÃ©rabilitÃ©s.
Vous pouvez customiser vos rÃ¨gles afin de filtrer vos autorisations.

ğŸ‘‰ InsÃ©rez vos mÃ©triques favorites ici pour mesurer la qualitÃ© du code ou auditer du code ğŸ¤“
- Respect des ratios de la pyramide de tests,
- Respect de la clean architecture,
- Absence de code mort,
- Nombre de bugs,
- Seuil de complexitÃ© cyclomatique,
- MÃ©triques de sÃ©curitÃ© (nombre de failles/CVE dans le code ou les dÃ©pendances),
- MÃ©triques Accelerate (Lead time, MTTR, ...),
- ... 

ğŸ **Objectifs :**

```plaintext
> ğŸ•µï¸â€ Automatiser, c'est rendre automatique une action qui Ã©tait jusque-lÃ  manuelle ğŸ’ª
```

ğŸ‘‰ Commencez par essayer de mesurer la qualitÃ© du code en local ! 

Sur votre poste local, installez les outils suivant, mesurez la qualitÃ© de votre code en ligne de commande et affichez les rÃ©sultats de mesure en console avec :
- es-lint
- audit-ci
- sonar

ğŸ¯ Mesurez les indicateurs suivant sur vos postes, en local :

- Nombre de warnings sur le style du code avec es-lint,
- Faites des analyses de sÃ©curitÃ© avec audit-ci et sonar,

Comme prÃ©cÃ©demment, prenez en note :
- les prÃ©-requis : les commandes ou paquets que vous avez dÃ» installer pour pouvoir lancer les tests,
- la commande que vous avez exÃ©cuter pour lancer les tests,
- le rÃ©sultat attendu : logs affichÃ©s en console, fichiers de rapport produits, ...

Cela nous servira pour reproduire cela dans notre pipeline de CI dans le prochain exercice.

## Step 5 : Mesure de la qualitÃ© du code (CI)

```plaintext
ğŸ¯ Objectif : Je veux obtenir du feedback sur la qualitÃ© du code automatiquement Ã  chaque push d'un commit.
```

Le pipeline doit permettre 
- d'exÃ©cuter les tests avec Jest, 
- puis si les tests sont verts; exÃ©cuter les Ã©tapes de mesure la qualitÃ© du code dans un stage `code-quality` comme ceci :

![](./docs/exercice2-code-analysis.png)

- âœ… Le stage `code-quality` sera vert si votre base de code respecte les standards de es-lint, audit-ci, sonar (en bonus).
- ğŸ”´ Le stage `code-quality` sera rouge si l'un de ces outils d'analyse relÃ¨ve au moins 1 warning.

### Autoriser l'Ã©chec d'une step

Dans le TP suivant, nous allons ajouter une step supplÃ©mentaire au pipeline pour packager automatiquement l'application 
- si les tests sont verts,
- et si le code produit est "de qualitÃ© suffisante".

En l'Ã©tat, le code Python n'est pas "parfait" concernant les outils d'analyse que nous utilisons : il y a quelques warnings notables avec jest et sonar par exemple.

S'il est utile de savoir que ces warnings existent, et qu'il faudra les corriger, nous ne souhaitons pas pour autant que le pipeline de CI s'arrÃªte sur cette Ã©tape `code-quality`.

Pour permettre au pipeline de continuer, github propose la fonctionnalitÃ© [continue-on-error](https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepscontinue-on-error).

ğŸ **Objectif : utilisez la fonctionnalitÃ© _continue-on-error_ sur le stage `code-quality` pour permettre au pipeline de ne pas s'arrÃªter mÃªme s'il Ã©choue sur celui-ci.**

**Rendu attendu** :

- âœ… Le stage `code-quality` sera vert si votre base de code respecte les standards de es-lint, audit-ci, sonar (en bonus).
- âš ï¸ Le stage `code-quality` sera orange si l'un de ces outils d'analyse relÃ¨ve au moins 1 warning.

- ![](./docs/exercice2-allow-failure.png)

## TP 6 : Packager du code de qualitÃ© (local)

```plaintext
ğŸ¯ Objectif : Je veux packager du code automatiquement.
```

```shell
cd func-dojo-cicd-skool;
npm run build
```
ğŸ **Objectif 1 : Packagez l'application en local.**

ğŸœ Test de recette : un dossier de la fonction devrait Ãªtre apparu dans le dossier dist/ â—ï¸

ğŸ **Objectif 2 : Changez la version de l'application en 1.18.27 avant de la packager.**

â„¹ï¸ Tips: vous pouvez utiliser la commande ```npm version patch``` \
ğŸœ Test de recette : le package possÃ¨de la version **1.18.27**, use ```npm version```

## TP 7 : Packager du code de qualitÃ© (en CI)

```plaintext
ğŸ¯ Objectif : je veux packager du code automatiquement Ã  chaque push d'un commit, si et seulement si les tests passent et la qualitÃ© du code est acceptable.
```

Le pipeline doit permettre 
- d'Ã©xÃ©cuter les tests avec jest, 
- puis si les tests sont verts : exÃ©cuter les Ã©tapes de mesure la qualitÃ© du code dans un stage `code-quality`
- puis si les tests sont verts et la qualitÃ© OK : packager le code et bump la version.

ğŸ **Objectif 1 : Packagez l'application en local au format Wheel.**

ğŸœ Test de recette : une nouvelle step `package-function` un nouveau stage `build` dans le pipeline de CI doit permettre de produire un dossier comme ceci : 

![](./docs/exercice3-build-stage.png)

ï¸ğŸ **Objectif 2 : Rendre le package accessible en artÃ©fact.**

ğŸœ Test de recette : la step `package-function` doit exposer le contenu du dossier dist/ en artÃ©fact afin de rendre le dossier tÃ©lÃ©chargeable depuis l'interface web : 

![](./docs/exercice3-build-artifact.png)

## BONUS : Deployer son artefact sur Azure (en CD)

```plaintext
ğŸ¯ Objectif : Je veux deployer mon artefact sur Azure
```

Dans ce dernier step Bonus, vous Ãªtes en autonomie. 
Nous voulons dÃ©ployer notre fonction sur un service Azure (Azure Function App). Pour ce faire, modifiez le code Terraform pour crÃ©er votre Azf et les resources nÃ©cessaires.
Dans un nouveau stage `deploy`, lancer les commandes Terraform requis et publier votre artefact.

â›”ï¸ Important : Ne changez pas les skus du Terraform. Les resources doivent rester en free tier.

ğŸœ Test de recette : Une Azure Function App est dÃ©ployÃ©e sur le cloud et je peux appeler ma fonction en Http.